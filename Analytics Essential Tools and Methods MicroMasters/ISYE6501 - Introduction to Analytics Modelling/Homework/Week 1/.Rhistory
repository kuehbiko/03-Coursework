# import relevant libraries
library(kernlab)
library(kknn)
# load data
df = read.delim('week 1 data-summer/data 2.2/credit_card_data-headers.txt')
#head(dataframe, 5)
# looping over values of C
logC <- c(-25:25)
c_vals <- 10^(-25:25)
accuracy_vector <- vector("numeric")
# build a svm for every value of C
set.seed(42)
for(c in c_vals) {
model <- ksvm(as.matrix(df[, 1:10]),
as.factor(df[, 11]),
type="C-svc",
kernel="vanilladot",
C=c,
scaled=T)
# get inidividual predictions
pred <- predict(model, df[,1:10])
# calculate accuracy of SVM model
accuracy <- sum(pred == df[, 11]) / nrow(df)
# store accuracy in accuracy vector
accuracy_vector <- c(accuracy_vector, accuracy)
}
# plotting accuracy against values of logC
plot(logC, accuracy_vector,
xlab="Log(C)",
ylab="Accuracy")
# highest accuracy
max(accuracy_vector)
# vector index for best value of C
which(accuracy_vector == max(accuracy_vector))
# build new svm with C=1
set.seed(42)
model <- ksvm(as.matrix(df[, 1:10]),
as.factor(df[, 11]),
type="C-svc",
kernel="vanilladot",
C = 1,
scaled=T)
# calculate coeffs
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
a
# calculate intercept
a0 <- -model@b
a0
# viewing predictions
pred <- predict(model,df[,1:10])
pred
myKernels <- c("vanilladot","polydot","besseldot", "laplacedot", "rbfdot", "tanhdot", "anovadot", "splinedot")
accuracy_vector <- vector("numeric")
set.seed(42)
for(i in 1:length(myKernels)){
model <-  ksvm(as.matrix(df[,1:10]),
as.factor(df[,11]),
type="C-svc",
kernel=myKernels[[i]],
C=1,
scaled=T)
# get predictions
pred <- predict(model,df[,1:10])
# get accuracy
accuracy <- sum(pred == df[, 11]) / nrow(df)
# store accuracy of each kernel in accuracy vector
accuracy_vector <- c(accuracy_vector, accuracy)
}
# create dataframe
df_2 <- data.frame(kernels = unlist(myKernels),
accuracy_score = unlist(accuracy_vector))
# plot a horizontal barplot
barplot(df_2$accuracy_score ~ df_2$kernels,
horiz=T,
las=2,
cex.names=0.6,
xlab="Accuracy",
ylab="Kernels")
# view full dataframe
df_2
pred <- vector(length=nrow(df)) # initialize empty vector
accuracy_vector <- vector("numeric")
# loop over values of k
# build knn model for each value of k
set.seed(42)
for (K in 1:50) {
for (i in 1:nrow(df)) {
model <- kknn(formula=df[-i,11]~.,
df[-i,1:10], #train (without ith data point)
df[i,1:10],  #test (with ith data point)
k=K,
kernel="rectangular",
scale=T)
# fill pred vector with predictions
pred[i] <- round(predict(model)) # round pred to 1 or 0
# get accuracy
accuracy <- sum(pred == df[,11]) / nrow(df)
}
# store accuracy for each k value in accuracy vector
accuracy_vector <- c(accuracy_vector, accuracy)
}
# plotting accuracy against values of k
plot(accuracy_vector,
xlab="k",
ylab="Accuracy")
# highest accuracy
max(accuracy_vector)
# best value of k
which(accuracy_vector == max(accuracy_vector))
# k-fold cross validation with cv.kknn
accuracy_vector <- vector("numeric")
set.seed(42)
for (K in 1:50) {
kmodel3 <- cv.kknn(formula=R1~.,
df,
kcv=10, # k-fold cross validation
k=K,
kernel="rectangular",
scale=T)
kmodel3 <- data.frame(kmodel3)
kmodelpred2 <- kmodel3[,2] # preds in 2nd col
rpred2 <- round(kmodelpred2) # round to 1 or 0
accuracy <- sum(rpred2 == df[,11]) / nrow(df)
accuracy_vector <- c(accuracy_vector, accuracy)
}
# plot accuracy for each value of k
plot(accuracy_vector,
xlab="k",
ylab="Accuracy")
# max accuracy
max(accuracy_vector)
# best value of k
which(accuracy_vector == max(accuracy_vector))
# splitting data with splitTools
# https://cran.r-project.org/web/packages/splitTools/vignettes/splitTools.html
library(splitTools)
# split data into partitions
set.seed(42)
split_data <- partition(df$R1, p = c(train = 0.6, valid = 0.2, test = 0.2))
df_train <- df[split_data$train, ]
df_valid <- df[split_data$valid, ]
df_test <- df[split_data$test, ]
# train an svm
set.seed(42)
svm_model <- ksvm(as.matrix(df_train[, 1:10]),
as.factor(df_train[, 11]),
type="C-svc",
kernel="splinedot",
C=1,
scaled=T)
# train a knn
set.seed(42)
knn_model <- train.kknn(as.factor(R1)~.,
df_train,
ks = 22,
kernel="rectangular",
scale=T)
# validate each model
svm_valid_pred <- predict(svm_model, df_valid[,1:10])
knn_valid_pred <- predict(knn_model, df_valid[,1:10])
svm_valid_acc <- sum(svm_valid_pred == df_valid[, 11]) / nrow(df_valid)
knn_valid_acc <- sum(knn_valid_pred == df_valid[, 11]) / nrow(df_valid)
# compare validation accuracies
valid_acc <- c(svm_valid_acc, knn_valid_acc)
valid_acc
# predicting based on test data
test_pred <- predict(knn_model, df_test[,1:10])
test_acc <- sum(test_pred == df_test[, 11]) / nrow(df_test)
test_acc
knn_model <- train.kknn(as.factor(R1)~.,
df_train,
ks = 7,
kernel="rectangular",
scale=T)
# validate each model
svm_valid_pred <- predict(svm_model, df_valid[,1:10])
knn_valid_pred <- predict(knn_model, df_valid[,1:10])
svm_valid_acc <- sum(svm_valid_pred == df_valid[, 11]) / nrow(df_valid)
knn_valid_acc <- sum(knn_valid_pred == df_valid[, 11]) / nrow(df_valid)
# compare validation accuracies
valid_acc <- c(svm_valid_acc, knn_valid_acc)
valid_acc
# predicting based on test data
test_pred <- predict(knn_model, df_test[,1:10])
test_acc <- sum(test_pred == df_test[, 11]) / nrow(df_test)
test_acc
---
title: "Week-1-homework"
install.packages('tinytex')
