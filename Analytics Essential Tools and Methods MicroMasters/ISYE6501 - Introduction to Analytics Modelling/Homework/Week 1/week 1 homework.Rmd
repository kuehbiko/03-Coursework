---
title: "Week 1 homework"
output: html_notebook
---

**Question 2.1** **Describe a situation or problem from your job, everyday life, current events, etc., for which a classification model would be appropriate. List some (up to 5) predictors that you might use.**

The stars have to align for me to actually do my homework so let's use a classifier to predict how likely it is that I will be working on my homework for any given day.

The question that the classifier answers: Will I be doing my homework today? (yes/no)

Some possible predictors:

1.  Did I wake up before 11am?
2.  Number of days that I have worked in a row? at a low number, it's harder to start. at a high number, there is a possibility of burnout setting in. (working day streak)
3.  Have I eaten today? yes - possibly higher chance of me working becuase i am not tired and grumpy

I think 5 predictors is not nearly enough to classify a day as a "homework day" or a "video game day", but there you have it.

**Question 2.2**

**The files credit_card_data.txt (without headers) and credit_card_data-headers.txt (with headers) contain a dataset with 654 data points, 6 continuous and 4 binary predictor variables.  It has anonymized credit card applications with a binary response variable (last column) indicating if the application was positive or negative. The dataset is the “Credit Approval Data Set” from the UCI Machine Learning Repository (<https://archive.ics.uci.edu/ml/datasets/Credit+Approval>) without the categorical variables and without data points that have missing values.**

```{r}
# import relevant libraries
library(kernlab)
library(kknn)
```

```{r}
# load data
df = read.delim('week 1 data-summer/data 2.2/credit_card_data-headers.txt')
head(dataframe, 5)
```

**Question 2.2 Part 1**

**Using the support vector machine function `ksvm` contained in the R package `kernlab`, find a good classifier for this data. Show the equation of your classifier, and how well it classifies the data points in the full data set. (Don’t worry about test/validation data yet; we’ll cover that topic soon.)**

For this question, we will be using the `ksvm` function in `kernlab` to classify the full credit card dataset.

First, we will want to find the optimal value of the regularization parameter `C`. In SVM, `C` is the parameter that controls the trade-off between maximizing the margin and minimizing the classification error [[1](https://www.analyticsvidhya.com/blog/2021/04/insight-into-svm-support-vector-machine-along-with-code/#:~:text=It%20introduces%20a%20regularization%20parameter,leading%20to%20a%20narrower%20margin.)]. A smaller value of C results in a larger margin [[2](https://medium.com/@pushkarmandot/what-is-the-significance-of-c-value-in-support-vector-machine-28224e852c5a)]. To tie this back in with the module 2 lectures, the parameter `C` is similar to the term $\lambda$.

To find this optimal value of C, we will loop over a range of values starting from 10e\^{-25} to 10e\^{25}. For each value of C, we construct an SVM model and calculate the corresponding accuracy, which is the ratio of the number of *correct* predictions to the total number of predictions. Then store each accuracy in a vector `accuracy_vector`.

We will use accuracy as the metric to determine the best classifier and thus the best value of C.

```{r}
# looping over values of C
logC <- c(-25:25)
c_vals <- 10^(-25:25)
accuracy_vector <- vector("numeric")

# build a svm for every value of C
for(c in c_vals) {
  model <- ksvm(as.matrix(df[, 1:10]),
                as.factor(df[, 11]),
                type="C-svc",
                kernel="vanilladot",
                C=c,
                scaled=T)
  
  pred <- predict(model, df[,1:10])
  accuracy <- sum(pred == df[, 11]) / nrow(df)
  accuracy_vector <- c(accuracy_vector, accuracy)
}
```

Then, plot the values in `accuracy_vector` against the values of $log(C)$:

```{r}
# plotting accuracy against values of logC
plot(logC, accuracy_vector, 
     xlab="Log(C)",
     ylab="Accuracy")
```

Use the `max()` function to find the highest accuracy in the vector.

```{r}
# highest accuracy
max(accuracy_vector)
```

Then use the `which()` function to find the index of the highest accuracy.

```{r}
# vector index for best value of C
which(accuracy_vector == max(accuracy_vector))
```

A higher C means more weight to correctness (post @58 in Piazza), so let's go ahead with the highest index, which corresponds to a value of C=10e5.

Now we refit the model with the selected C value.

```{r}
# build new svm with C=10e-2
model <- ksvm(as.matrix(df[, 1:10]),
              as.factor(df[, 11]),
              type="C-svc",
              kernel="vanilladot",
              C = 10000,
              scaled=T)
```

We can then obtain the coefficients and y-intercept of the classifier equation (code for both provided in the homework sheet).

```{r}
# calculate coeffs
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
a
```

```{r}
# calculate intercept
a0 <- -model@b
a0
```

Finally, we contruct the classifier equation:

$$
0 = 0.0008936167A_{1}+0.0016125725A_{2}-0.0003415921A_{3}+0.0042114213A_{8}+1.0014527518A_{9}+0.0023573637A_{10}+0.0052757867A_{11}+0.0002803662A_{12}+0.0025097815A_{14}+0.0035920442 A_{15}+0.07046104
$$

where $A_{1}$ to $A_{15}$ are the corresponding column labels.

Just to be sure, let's also view all the predictions made by our model.

```{r}
# viewing predictions
pred <- predict(model,df[,1:10])
pred
```

**Question 2.2 Part 2**

**You are welcome, but not required, to try other (nonlinear) kernels as well; we’re not covering them in this course, but they can sometimes be useful and might provide better predictions than `vanilladot.`**

For this question, let's first understand what kernels are.

A kernel is a set of mathematical functions used to map input data points into a higher-dimensional space where the separation between two classes becomes easier. This allows SVM to solve complex non-linear problems. [[source](https://medium.com/@Suraj_Yadav/what-is-kernel-trick-in-svm-interview-questions-related-to-kernel-trick-97674401c48d)]

The `kernel` parameter in `ksvm` accepts a list of kernels that can be found in their [documentation](https://www.rdocumentation.org/packages/kernlab/versions/0.9-32/topics/ksvm):

-   **`rbfdot`** Radial Basis kernel "Gaussian"

-   **`polydot`** Polynomial kernel

-   **`vanilladot`** Linear kernel

-   **`tanhdot`** Hyperbolic tangent kernel

-   **`laplacedot`** Laplacian kernel

-   **`besseldot`** Bessel kernel

-   **`anovadot`** ANOVA RBF kernel

-   **`splinedot`** Spline kernel

-   **`stringdot`** String kernel

The `stringdot` kernel specifically is used for string data. As we are dealing only with numerical data, this kernel is not suited to our data and thus will be excluded from the comparison.

To find the best performing kernel, we will loop through a list of kernels and create a SVM using each kernel. Similar to the process in Q2.2.1, we will use accuracy as the metric for determining the best kernel for our model. Accuracy will be calculated for each SVM, then stored in the accuracy vector.

```{r}
myKernels <- c("vanilladot","polydot","besseldot", "laplacedot", "rbfdot", "tanhdot", "anovadot", "splinedot")
accuracy_vector <- vector("numeric")

for(i in 1:length(myKernels)){
  model <-  ksvm(as.matrix(df[,1:10]),
                 as.factor(df[,11]),
                 type="C-svc",
                 kernel=myKernels[[i]],
                 C=10000,
                 scaled=T)

  # get predictions
  pred <- predict(model,df[,1:10])
  # get accuracy
  accuracy <- sum(pred == df[, 11]) / nrow(df)
  # store accuracy of each kernel in accuracy vector
  accuracy_vector <- c(accuracy_vector, accuracy)
}
```

Next, we will create a dataframe with the list of kernels and their corresponding accuracies. Once this is done, we can plot our data as bar chart to visualize it.

```{r}
# create dataframe
df_2 <- data.frame(kernels = unlist(myKernels),
                   accuracy_score = unlist(accuracy_vector))

# plot a horizontal barplot
barplot(df_2$accuracy_score ~ df_2$kernels, 
        horiz=T, 
        las=2,
        cex.names=0.6,
        xlab="Accuracy",
        ylab="Kernels")
```

From the bar chart, we observe that our top performers are the `splinedot`, `rbfdot` and `laplacedot` kernels.

Let's also take a closer look at the accuracy values from the dataframe:

```{r}
# view full dataframe
df_2
```

Interestingly, the `laplacedot` kernel has managed to achieve a perfect accuracy score of 1! This suggests a high probability of overfitting.

**Question 2.2 Part 3**

**Using the k-nearest-neighbors classification function `kknn` contained in the R `kknn` package, suggest a good value of k, and show how well it classifies that data points in the full data set. Don’t forget to scale the data (`scale=TRUE in kknn`).**

For this question, we will be using the `kknn` function in the `kknn` package to classify the credit card dataset.

We will want to find the optimal value of k, which represents the k number of neighbouring data points that will be used to classify a new data point.

Just like in Q2.2.1, to find this optimal value of k, we will loop over a range of values from 1 to 50 and create a KNN model for each k value.

For each value of k, we calculate the corresponding accuracy, which is the ratio of the number of *correct* predictions to the total number of predictions. We will use accuracy as the metric to determine the best classifier and thus the best value of k.

At the end of the loop, store the accuracy of the model in a vector called `accuracy_vector`.

However, before we do anything, we need to initialize an empty vector the same length as the number of rows of the dataset in order to store each prediction generated by the KNN model. [[source](https://stackoverflow.com/questions/61829843/how-to-access-values-of-predict-function-in-r-for-storage)]

Because kknn returns predictions as a continuous variable instead of purely 1s and 0s, round each output to 1/0 and store in the prediction vector we made earlier

```{r}
pred <- vector(length=nrow(df)) # initialize empty vector
accuracy_vector <- vector("numeric") 

# loop over values of k
# build knn model for each value of k
for (K in 1:50) {
  for (i in 1:nrow(df)) {
    model <- kknn(formula=df[-i,11]~.,
                  df[-i,1:10], #train (without ith data point)
                  df[i,1:10],  #test (with ith data point)
                  k=K, 
                  kernel="rectangular",
                  scale=T)
    
    # fill pred vector with predictions 
    pred[i] <- round(predict(model)) # round pred to 1 or 0
    # get accuracy
    accuracy <- sum(pred == df[,11]) / nrow(df)
  }
  
  # store accuracy for each k value in accuracy vector
  accuracy_vector <- c(accuracy_vector,accuracy)
}
```

Then, plot the values in `accuracy_vector` against the values of k.

```{r}
# plotting accuracy against values of k
plot(accuracy_vector,
     xlab="k",
     ylab="Accuracy")
```

Use the `max()` function to find the highest accuracy in the vector.

```{r}
# highest accuracy
max(accuracy_vector)
```

Then use the `which()` function to find the index of the highest accuracy.

```{r}
# best value of k
which(accuracy_vector == max(accuracy_vector))
```

Thus we can suggest a value of k=12 to be optimal, because it results in the highest accuracy of 0.853211.

**Question 3.1 Using the same data set (credit_card_data.txt or credit_card_data-headers.txt) as in Question 2.2, use the ksvm or kknn function to find a good classifier. a) Using cross-validation (do this for the k-nearest-neighbors model; SVM is optional)**

For this question, we will be training KNN models with k-fold cross validation using the `cv.kknn` function from the `kknn` package. We will use a 10-fold cross validation.

Using the same method as the previous question, we will simply loop through 50 values of k, calculate the accuracy, store these accuracy values in our accuracy vector, then use the highest accuracy to select the optimal value of k.

```{r}
# k-fold cross validation with cv.kknn

accuracy_vector <- vector("numeric")

for (K in 1:50) {
  kmodel3 <- cv.kknn(formula=R1~.,
                     df,
                     kcv=10, # k-fold cross validation
                     k=K, 
                     kernel="rectangular",
                     scale=T)
  kmodel3 <- data.frame(kmodel3) 
  kmodelpred2 <- kmodel3[,2] # preds in 2nd col
  rpred2 <- round(kmodelpred2) # round to 1 or 0
  accuracy <- sum(rpred2 == df[,11]) / nrow(df) 
  accuracy_vector <- c(accuracy_vector, accuracy) 
}
```

Then, plot the values in `accuracy_vector` against the values of k

```{r}
# plot accuracy for each value of k
plot(accuracy_vector,
     xlab="k",
     ylab="Accuracy")
```

Use the `max()` function to find the highest accuracy in the vector.

```{r}
# max accuracy
max(accuracy_vector)
```

Then use the `which()` function to find the index of the highest accuracy.

```{r}
# best value of k
which(accuracy_vector == max(accuracy_vector))
```

Thus we can suggest a value of k=11 to be optimal, because it results in the highest accuracy of 0.8577982.

**b) Splitting the data into training, validation, and test data sets (pick either KNN or SVM; the other is optional)**

For this questions, we will use the `splitTools` package to split our data into train, validation and test datasets. We will use 60% of the data for training, 20% for validation and 20% for testing.

```{r}
# splitting data with splitTools
# https://cran.r-project.org/web/packages/splitTools/vignettes/splitTools.html
library(splitTools)

# split data into partitions
set.seed(42)
split_data <- partition(df$R1, p = c(train = 0.6, valid = 0.2, test = 0.2))

df_train <- df[split_data$train, ]
df_valid <- df[split_data$valid, ]
df_test <- df[split_data$test, ]
```

Let's train an SVM with the train dataset using the best value of C that we found earlier.

```{r}
# train an svm
svm_model <- ksvm(as.matrix(df_train[, 1:10]),
              as.factor(df_train[, 11]),
              type="C-svc",
              kernel="vanilladot",
              C=100000,
              scaled=T)
```

Now let's train a KNN model using the best value of k that we found earlier for the model *without* cross validation (this model does not use cross-validation, which is why we will use the k value from the model without cross-validation).

```{r}
# train a knn
knn_model <- train.kknn(as.factor(R1)~., 
                        df_train, 
                        ks = 12,
                        kernel="rectangular", 
                        scale=T)
```

```{r}
# validate each model
svm_valid_pred <- predict(svm_model, df_valid[,1:10])
knn_valid_pred <- predict(knn_model, df_valid[,1:10])

svm_valid_acc <- sum(svm_valid_pred == df_valid[, 11]) / nrow(df_valid)
knn_valid_acc <- sum(knn_valid_pred == df_valid[, 11]) / nrow(df_valid)
```

```{r}
# compare validation accuracies
valid_acc <- c(svm_valid_acc, knn_valid_acc)
valid_acc
```

```{r}
# predicting based on test data
test_pred <- predict(svm_model, df_test[,1:10])
test_acc <- sum(test_pred == df_test[, 11]) / nrow(df_test)
test_acc
```

The SVM model is a better model for our data due to its higher performance on the validation set compared to KNN model. When testing the SVM model on the test dataset, our model has an accuracy of 0.8167939 down from the accuracy of 0.8473282 from the validation set.
